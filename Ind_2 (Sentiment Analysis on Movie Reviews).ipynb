{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score\n",
    "\n",
    "import nltk\n",
    "\n",
    "import unicodedata, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation and analisys of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('train.tsv', '\\t')\n",
    "test = pd.read_csv('test.tsv', '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (156060, 4)\n",
      "Test: (66292, 3)\n"
     ]
    }
   ],
   "source": [
    "# shapes of datasets\n",
    "print(\"Train :\",train.shape)\n",
    "print(\"Test:\",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колонка ['Sentiment'] містить оцінку коментаря (від 0 до 4). Відповідно:\n",
    "\n",
    "0 - негативний;\n",
    "1 - трохи негативний;\n",
    "2 - нейтральний;\n",
    "3 - трохи позитивний;\n",
    "4 - позитивний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Phrase'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get columns with NULLs  (if exist)\n",
    "train.columns[train.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оглянемо, скільки фраз належить до одного речення (наприклад, до речення 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>This</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>quiet , introspective and entertaining indepen...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>quiet , introspective and entertaining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>quiet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>, introspective and entertaining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>introspective and entertaining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>introspective and</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>introspective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>independent</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>is worth seeking .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>is worth seeking</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>is worth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>worth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>seeking</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "63        64           2  This quiet , introspective and entertaining in...   \n",
       "64        65           2  This quiet , introspective and entertaining in...   \n",
       "65        66           2                                               This   \n",
       "66        67           2  quiet , introspective and entertaining indepen...   \n",
       "67        68           2             quiet , introspective and entertaining   \n",
       "68        69           2                                              quiet   \n",
       "69        70           2                   , introspective and entertaining   \n",
       "70        71           2                     introspective and entertaining   \n",
       "71        72           2                                  introspective and   \n",
       "72        73           2                                      introspective   \n",
       "73        74           2                                                and   \n",
       "74        75           2                                       entertaining   \n",
       "75        76           2                                        independent   \n",
       "76        77           2                                 is worth seeking .   \n",
       "77        78           2                                   is worth seeking   \n",
       "78        79           2                                           is worth   \n",
       "79        80           2                                              worth   \n",
       "80        81           2                                            seeking   \n",
       "\n",
       "    Sentiment  \n",
       "63          4  \n",
       "64          3  \n",
       "65          2  \n",
       "66          4  \n",
       "67          3  \n",
       "68          2  \n",
       "69          3  \n",
       "70          3  \n",
       "71          3  \n",
       "72          2  \n",
       "73          2  \n",
       "74          4  \n",
       "75          2  \n",
       "76          3  \n",
       "77          4  \n",
       "78          2  \n",
       "79          2  \n",
       "80          2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_2 = train.loc[train['SentenceId'] == 2]\n",
    "print(len(sentence_2))\n",
    "sentence_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns[test.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "І в тренувальному, і в тестувальному датасеті відсутні нульові значення, тому не потрібно виконувати їхню додаткову обробку.\n",
    "\n",
    "Відслідкуємо кількість фраз за оцінкою:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = train.groupby([\"Sentiment\"]).size()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.barplot(dist.keys(), dist.values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оскільки на оцінку коментаря (негативний/позитивний) впливають лише слова у фразі, то саме з них і сформуємо матрицю властивостей (feature matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = train['Phrase'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормалізуємо дані:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-ASCII characters\n",
    "def remove_non_ascii(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "# All words to lowercase\n",
    "def to_lowercase(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "# Remove punctuation\n",
    "def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "# Remove all numbers\n",
    "def remove_numbers(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(\"\\d+\", \"\", word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_numbers(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [a, series, of, escapades, demonstrating, the,...\n",
       "1    [a, series, of, escapades, demonstrating, the,...\n",
       "2                                          [a, series]\n",
       "3                                                  [a]\n",
       "4                                             [series]\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = words.apply(normalize) \n",
    "words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Створимо словник унікальних слів:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mission': 1,\n",
       " 'deftly': 2,\n",
       " 'illuminate': 3,\n",
       " 'fifteenminute': 4,\n",
       " 'actress': 5,\n",
       " 'undramatic': 6,\n",
       " 'lola': 7,\n",
       " 'wisegirls': 8,\n",
       " 'timeitis': 9,\n",
       " 'facet': 10,\n",
       " 'amazement': 11,\n",
       " 'foot': 12,\n",
       " 'twofifths': 13,\n",
       " 'gamut': 14,\n",
       " 'sitcomishly': 15,\n",
       " 'shaken': 16,\n",
       " 'obligatory': 17,\n",
       " 'unsympathetic': 18,\n",
       " 'drew': 19,\n",
       " 'transform': 20,\n",
       " 'terminal': 21,\n",
       " 'inescapably': 22,\n",
       " 'conscious': 23,\n",
       " 'indignation': 24,\n",
       " 'swear': 25,\n",
       " 'avenues': 26,\n",
       " 'breaks': 27,\n",
       " 'elbowed': 28,\n",
       " 'imaginative': 29,\n",
       " 'uncover': 30,\n",
       " 'denzel': 31,\n",
       " 'drowns': 32,\n",
       " 'mendes': 33,\n",
       " 'dalloway': 34,\n",
       " 'pillages': 35,\n",
       " 'unnecessary': 36,\n",
       " 'canon': 37,\n",
       " 'orientation': 38,\n",
       " 'celebrated': 39,\n",
       " 'billy': 40,\n",
       " 'horror': 41,\n",
       " 'france': 42,\n",
       " 'funniness': 43,\n",
       " 'share': 44,\n",
       " 'undergraduate': 45,\n",
       " 'audacity': 46,\n",
       " 'dramedy': 47,\n",
       " 'morphs': 48,\n",
       " 'depend': 49,\n",
       " 'groupies': 50,\n",
       " 'shiver': 51,\n",
       " 'cd': 52,\n",
       " 'distinguishing': 53,\n",
       " 'orlando': 54,\n",
       " 'clive': 55,\n",
       " 'appalling': 56,\n",
       " 'lear': 57,\n",
       " 'flash': 58,\n",
       " 'words': 59,\n",
       " 'promotes': 60,\n",
       " 'fincher': 61,\n",
       " 'abject': 62,\n",
       " 'vexing': 63,\n",
       " 'confection': 64,\n",
       " 'disreputable': 65,\n",
       " 'distort': 66,\n",
       " 'permission': 67,\n",
       " 'getgo': 68,\n",
       " 'interdependence': 69,\n",
       " 'preaching': 70,\n",
       " 'pollyana': 71,\n",
       " 'resentful': 72,\n",
       " 'beware': 73,\n",
       " 'stylefree': 74,\n",
       " 'excruciating': 75,\n",
       " 'colonics': 76,\n",
       " 'eke': 77,\n",
       " 'seater': 78,\n",
       " 'discount': 79,\n",
       " 'generous': 80,\n",
       " 'absolutely': 81,\n",
       " 'describes': 82,\n",
       " 'cherry': 83,\n",
       " 'kosminsky': 84,\n",
       " 'interpretations': 85,\n",
       " 'burlesque': 86,\n",
       " 'hustler': 87,\n",
       " 'asked': 88,\n",
       " 'sleek': 89,\n",
       " 'born': 90,\n",
       " 'satirical': 91,\n",
       " 'drizzle': 92,\n",
       " 'selfaware': 93,\n",
       " 'affirming': 94,\n",
       " 'quixotic': 95,\n",
       " 'chief': 96,\n",
       " 'rockumentary': 97,\n",
       " 'appreciated': 98,\n",
       " 'metropolis': 99,\n",
       " 'filming': 100,\n",
       " 'product': 101,\n",
       " 'murderous': 102,\n",
       " 'spicy': 103,\n",
       " 'curtsy': 104,\n",
       " 'learns': 105,\n",
       " 'denver': 106,\n",
       " 'scotland': 107,\n",
       " 'charms': 108,\n",
       " 'barbarian': 109,\n",
       " 'fangbaring': 110,\n",
       " 'revenge': 111,\n",
       " 'majorleague': 112,\n",
       " 'unspool': 113,\n",
       " 'devastating': 114,\n",
       " 'brits': 115,\n",
       " 'notatallgood': 116,\n",
       " 'anew': 117,\n",
       " 'customarily': 118,\n",
       " 'knowledge': 119,\n",
       " 'antwone': 120,\n",
       " 'text': 121,\n",
       " 'nail': 122,\n",
       " 'nature': 123,\n",
       " 'depressingly': 124,\n",
       " 'vietnam': 125,\n",
       " 'grounds': 126,\n",
       " 'jr': 127,\n",
       " 'erotically': 128,\n",
       " 'hitandmiss': 129,\n",
       " 'seaside': 130,\n",
       " 'sucks': 131,\n",
       " 'amused': 132,\n",
       " 'strangeness': 133,\n",
       " 'games': 134,\n",
       " 'preceded': 135,\n",
       " 'filmgoing': 136,\n",
       " 'tics': 137,\n",
       " 'amiably': 138,\n",
       " 'ben': 139,\n",
       " 'mason': 140,\n",
       " 'vitality': 141,\n",
       " 'cut': 142,\n",
       " 'denying': 143,\n",
       " 'interaction': 144,\n",
       " 'selfsatisfied': 145,\n",
       " 'letter': 146,\n",
       " 'ethnographic': 147,\n",
       " 'watchable': 148,\n",
       " 'sales': 149,\n",
       " 'thumpingly': 150,\n",
       " 'bibi': 151,\n",
       " 'spies': 152,\n",
       " 'farewelltoinnocence': 153,\n",
       " 'have': 154,\n",
       " 'fail': 155,\n",
       " 'eisenstein': 156,\n",
       " 'humorously': 157,\n",
       " 'doodled': 158,\n",
       " 'campus': 159,\n",
       " 'dimension': 160,\n",
       " 'enveloping': 161,\n",
       " 'delighted': 162,\n",
       " 'disappointing': 163,\n",
       " 'selfconsciously': 164,\n",
       " 'lured': 165,\n",
       " 'fullfledged': 166,\n",
       " 'stalls': 167,\n",
       " 'trancenoir': 168,\n",
       " 'romanced': 169,\n",
       " 'balding': 170,\n",
       " 'grandiose': 171,\n",
       " 'misses': 172,\n",
       " 'dalrymple': 173,\n",
       " 'saga': 174,\n",
       " 'swordandsorcery': 175,\n",
       " 'manners': 176,\n",
       " 'resolution': 177,\n",
       " 'subversive': 178,\n",
       " 'tightrope': 179,\n",
       " 'pathology': 180,\n",
       " 'ungainly': 181,\n",
       " 'urges': 182,\n",
       " 'spectator': 183,\n",
       " 'locale': 184,\n",
       " 'respectively': 185,\n",
       " 'bod': 186,\n",
       " 'aged': 187,\n",
       " 'splitscreen': 188,\n",
       " 'save': 189,\n",
       " 'pleasures': 190,\n",
       " 'concubine': 191,\n",
       " 'protagonist': 192,\n",
       " 'event': 193,\n",
       " 'uncomfortable': 194,\n",
       " 'misdirected': 195,\n",
       " 'cheek': 196,\n",
       " 'humanscale': 197,\n",
       " 'small': 198,\n",
       " 'aspirations': 199,\n",
       " 'porno': 200,\n",
       " 'searches': 201,\n",
       " 'clutches': 202,\n",
       " 'vice': 203,\n",
       " 'wasp': 204,\n",
       " 'titlebout': 205,\n",
       " 'painters': 206,\n",
       " 'prowess': 207,\n",
       " 'stench': 208,\n",
       " 'reworking': 209,\n",
       " 'tasty': 210,\n",
       " 'sale': 211,\n",
       " 'misadventures': 212,\n",
       " 'closet': 213,\n",
       " 'hypocritical': 214,\n",
       " 'witty': 215,\n",
       " 'hairdo': 216,\n",
       " 'postcard': 217,\n",
       " 'rejected': 218,\n",
       " 'ills': 219,\n",
       " 'woe': 220,\n",
       " 'rekindles': 221,\n",
       " 'drumline': 222,\n",
       " 'norwegian': 223,\n",
       " 'blob': 224,\n",
       " 'antikieslowski': 225,\n",
       " 'belittle': 226,\n",
       " 'growth': 227,\n",
       " 'kiddies': 228,\n",
       " 'preview': 229,\n",
       " 'astronomically': 230,\n",
       " 'crosssection': 231,\n",
       " 'selfdelusion': 232,\n",
       " 'wrestling': 233,\n",
       " 'horrific': 234,\n",
       " 'splendidlooking': 235,\n",
       " 'extralarge': 236,\n",
       " 'closeddoor': 237,\n",
       " 'gays': 238,\n",
       " 'spectacle': 239,\n",
       " 'followyourdream': 240,\n",
       " 'loose': 241,\n",
       " 'motions': 242,\n",
       " 'egomaniac': 243,\n",
       " 'hithungry': 244,\n",
       " 'dope': 245,\n",
       " 'banger': 246,\n",
       " 'picnic': 247,\n",
       " 'sepiatinted': 248,\n",
       " 'peerelated': 249,\n",
       " 'counterparts': 250,\n",
       " 'freddie': 251,\n",
       " 'phones': 252,\n",
       " 'tasteless': 253,\n",
       " 'firebreathing': 254,\n",
       " 'abundantly': 255,\n",
       " 'murk': 256,\n",
       " 'quickcut': 257,\n",
       " 'topnotch': 258,\n",
       " 'frenzy': 259,\n",
       " 'simmer': 260,\n",
       " 'melts': 261,\n",
       " 'bouts': 262,\n",
       " 'picked': 263,\n",
       " 'disappointed': 264,\n",
       " 'harris': 265,\n",
       " 'harmon': 266,\n",
       " 'indicate': 267,\n",
       " 'youth': 268,\n",
       " 'israel': 269,\n",
       " 'teethgnashing': 270,\n",
       " 'latenight': 271,\n",
       " 'beg': 272,\n",
       " 'potter': 273,\n",
       " 'hazy': 274,\n",
       " 'houses': 275,\n",
       " 'costly': 276,\n",
       " 'unfolds': 277,\n",
       " 'woodland': 278,\n",
       " 'thud': 279,\n",
       " 'football': 280,\n",
       " 'ennuihobbled': 281,\n",
       " 'struck': 282,\n",
       " 'censure': 283,\n",
       " 'shape': 284,\n",
       " 'lowrent': 285,\n",
       " 'appetizing': 286,\n",
       " 'legion': 287,\n",
       " 'misunderstood': 288,\n",
       " 'outoffield': 289,\n",
       " 'phlegmatic': 290,\n",
       " 'skills': 291,\n",
       " 'fizzability': 292,\n",
       " 'composer': 293,\n",
       " 'sitcom': 294,\n",
       " 'dismiss': 295,\n",
       " 'uglier': 296,\n",
       " 'hugescreen': 297,\n",
       " 'beachcombing': 298,\n",
       " 'nuance': 299,\n",
       " 'halle': 300,\n",
       " 'empowerment': 301,\n",
       " 'surveys': 302,\n",
       " 'scared': 303,\n",
       " 'treasured': 304,\n",
       " 'thereafter': 305,\n",
       " 'leers': 306,\n",
       " 'streetwise': 307,\n",
       " 'clown': 308,\n",
       " 'porthole': 309,\n",
       " 'dunst': 310,\n",
       " 'natalie': 311,\n",
       " 'goose': 312,\n",
       " 'artifice': 313,\n",
       " 'preoccupations': 314,\n",
       " 'induces': 315,\n",
       " 'simpsons': 316,\n",
       " 'observations': 317,\n",
       " 'naughty': 318,\n",
       " 'psychodramatics': 319,\n",
       " 'underlined': 320,\n",
       " 'kittenish': 321,\n",
       " 'partnerships': 322,\n",
       " 'bees': 323,\n",
       " 'accepts': 324,\n",
       " 'selfesteem': 325,\n",
       " 'tykwer': 326,\n",
       " 'orleans': 327,\n",
       " 'catharsis': 328,\n",
       " 'intent': 329,\n",
       " 'recovered': 330,\n",
       " 'piecing': 331,\n",
       " 'depicts': 332,\n",
       " 'beattheclock': 333,\n",
       " 'enough': 334,\n",
       " 'remakes': 335,\n",
       " 'navelgazing': 336,\n",
       " 'suckers': 337,\n",
       " 'strangest': 338,\n",
       " 'proceeds': 339,\n",
       " 'fraser': 340,\n",
       " 'legally': 341,\n",
       " 'trap': 342,\n",
       " 'formalist': 343,\n",
       " 'sung': 344,\n",
       " 'finish': 345,\n",
       " 'boorish': 346,\n",
       " 'rivalry': 347,\n",
       " 'grandstanding': 348,\n",
       " 'nearmiss': 349,\n",
       " 'schindler': 350,\n",
       " 'machine': 351,\n",
       " 'tangents': 352,\n",
       " 'supersimple': 353,\n",
       " 'bungling': 354,\n",
       " 'agesold': 355,\n",
       " 'artists': 356,\n",
       " 'widescreen': 357,\n",
       " 'rohmer': 358,\n",
       " 'delectable': 359,\n",
       " 'waferthin': 360,\n",
       " 'ai': 361,\n",
       " 'feed': 362,\n",
       " 'mediaconstructed': 363,\n",
       " 'anxious': 364,\n",
       " 'urgency': 365,\n",
       " 'sporadically': 366,\n",
       " 'megaplexes': 367,\n",
       " 'sardonic': 368,\n",
       " 'documentarymaking': 369,\n",
       " 'unrequited': 370,\n",
       " 'janklowiczmann': 371,\n",
       " 'session': 372,\n",
       " 'acquires': 373,\n",
       " 'demonic': 374,\n",
       " 'uninhibited': 375,\n",
       " 'pin': 376,\n",
       " 'familyfilm': 377,\n",
       " 'liza': 378,\n",
       " 'dolman': 379,\n",
       " 'groan': 380,\n",
       " 'both': 381,\n",
       " 'twohy': 382,\n",
       " 'mention': 383,\n",
       " 'battered': 384,\n",
       " 'public': 385,\n",
       " 'blossom': 386,\n",
       " 'essay': 387,\n",
       " 'improves': 388,\n",
       " 'illtimed': 389,\n",
       " 'candycoat': 390,\n",
       " 'marivaux': 391,\n",
       " 'brazenly': 392,\n",
       " 'bowling': 393,\n",
       " 'powered': 394,\n",
       " 'serials': 395,\n",
       " 'daddy': 396,\n",
       " 'achieves': 397,\n",
       " 'hardcore': 398,\n",
       " 'corrupt': 399,\n",
       " 'designed': 400,\n",
       " 'villeneuve': 401,\n",
       " 'board': 402,\n",
       " 'opposites': 403,\n",
       " 'add': 404,\n",
       " 'sorority': 405,\n",
       " 'highly': 406,\n",
       " 'claude': 407,\n",
       " 'poetics': 408,\n",
       " 'convenience': 409,\n",
       " 'rare': 410,\n",
       " 'technologies': 411,\n",
       " 'melt': 412,\n",
       " 'allout': 413,\n",
       " 'submerging': 414,\n",
       " 'cowritten': 415,\n",
       " 'koshashvili': 416,\n",
       " 'marks': 417,\n",
       " 'mounted': 418,\n",
       " 'diane': 419,\n",
       " 'benshan': 420,\n",
       " 'weaned': 421,\n",
       " 'aloft': 422,\n",
       " 'ears': 423,\n",
       " 'hail': 424,\n",
       " 'friggin': 425,\n",
       " 'interference': 426,\n",
       " 'indifferent': 427,\n",
       " 'ardor': 428,\n",
       " 'thecash': 429,\n",
       " 'bart': 430,\n",
       " 'setup': 431,\n",
       " 'mein': 432,\n",
       " 'americanrussian': 433,\n",
       " 'swooning': 434,\n",
       " 'welcome': 435,\n",
       " 'palma': 436,\n",
       " 'harlem': 437,\n",
       " 'reinvention': 438,\n",
       " 'maiden': 439,\n",
       " 'crimen': 440,\n",
       " 'bmovie': 441,\n",
       " 'term': 442,\n",
       " 'globe': 443,\n",
       " 'tennessee': 444,\n",
       " 'masked': 445,\n",
       " 'haunting': 446,\n",
       " 'discards': 447,\n",
       " 'savage': 448,\n",
       " 'asit': 449,\n",
       " 'author': 450,\n",
       " 'horrors': 451,\n",
       " 'ritter': 452,\n",
       " 'stacy': 453,\n",
       " 'grit': 454,\n",
       " 'lovers': 455,\n",
       " 'plucks': 456,\n",
       " 'pizza': 457,\n",
       " 'adult': 458,\n",
       " 'limits': 459,\n",
       " 'escapade': 460,\n",
       " 'mind': 461,\n",
       " 'worthwhile': 462,\n",
       " 'gallo': 463,\n",
       " 'reunion': 464,\n",
       " 'handsomely': 465,\n",
       " 'domestic': 466,\n",
       " 'distinct': 467,\n",
       " 'procession': 468,\n",
       " 'kathy': 469,\n",
       " 'blustery': 470,\n",
       " 'roadandbuddy': 471,\n",
       " 'sica': 472,\n",
       " 'flavorful': 473,\n",
       " 'sportsmovie': 474,\n",
       " 'dramas': 475,\n",
       " 'sense': 476,\n",
       " 'blacklight': 477,\n",
       " 'blutarsky': 478,\n",
       " 'comprehend': 479,\n",
       " 'ensures': 480,\n",
       " 'partyhearty': 481,\n",
       " 'snowman': 482,\n",
       " 'relevant': 483,\n",
       " 'wasted': 484,\n",
       " 'reshaping': 485,\n",
       " 'contrivance': 486,\n",
       " 'convictions': 487,\n",
       " 'communitycollege': 488,\n",
       " 'sterling': 489,\n",
       " 'tvcops': 490,\n",
       " 'ran': 491,\n",
       " 'pageantry': 492,\n",
       " 'photo': 493,\n",
       " 'sugarcoated': 494,\n",
       " 'interrogation': 495,\n",
       " 'stomach': 496,\n",
       " 'hoary': 497,\n",
       " 'rachel': 498,\n",
       " 'dares': 499,\n",
       " 'hookups': 500,\n",
       " 'newton': 501,\n",
       " 'fortunately': 502,\n",
       " 'whoop': 503,\n",
       " 'movie': 504,\n",
       " 'siegel': 505,\n",
       " 'thus': 506,\n",
       " 'buffeted': 507,\n",
       " 'hinton': 508,\n",
       " 'blithe': 509,\n",
       " 'outdated': 510,\n",
       " 'theorist': 511,\n",
       " 'evenings': 512,\n",
       " 'crossover': 513,\n",
       " 'observe': 514,\n",
       " 'shakespearean': 515,\n",
       " 'hewitt': 516,\n",
       " 'diminishing': 517,\n",
       " 'use': 518,\n",
       " 'ernest': 519,\n",
       " 'libretto': 520,\n",
       " 'effectively': 521,\n",
       " 'bender': 522,\n",
       " 'lovebirds': 523,\n",
       " 'bubbly': 524,\n",
       " 'hilarious': 525,\n",
       " 'exuberance': 526,\n",
       " 'lifts': 527,\n",
       " 'garcia': 528,\n",
       " 'ambivalent': 529,\n",
       " 'sever': 530,\n",
       " 'dealers': 531,\n",
       " 'court': 532,\n",
       " 'newcomer': 533,\n",
       " 'nickelodeonesque': 534,\n",
       " 'wonderful': 535,\n",
       " 'sandwich': 536,\n",
       " 'thinlyconceived': 537,\n",
       " 'humiliation': 538,\n",
       " 'ape': 539,\n",
       " 'movements': 540,\n",
       " 'unconned': 541,\n",
       " 'zhuangzhuang': 542,\n",
       " 'light': 543,\n",
       " 'step': 544,\n",
       " 'baker': 545,\n",
       " 'stevens': 546,\n",
       " 'overnight': 547,\n",
       " 'forthright': 548,\n",
       " 'ha': 549,\n",
       " 'biblical': 550,\n",
       " 'you': 551,\n",
       " 'melancholy': 552,\n",
       " 'zombie': 553,\n",
       " 'downer': 554,\n",
       " 'particular': 555,\n",
       " 'transcendence': 556,\n",
       " 'ambrose': 557,\n",
       " 'theatrically': 558,\n",
       " 'duel': 559,\n",
       " 'controversial': 560,\n",
       " 'castles': 561,\n",
       " 'closure': 562,\n",
       " 'aimless': 563,\n",
       " 'used': 564,\n",
       " 'wryly': 565,\n",
       " 'produced': 566,\n",
       " 'intermittently': 567,\n",
       " 'driver': 568,\n",
       " 'antique': 569,\n",
       " 'superwealthy': 570,\n",
       " 'macaroni': 571,\n",
       " 'unbelievable': 572,\n",
       " 'outcome': 573,\n",
       " 'wisely': 574,\n",
       " 'prejudice': 575,\n",
       " 'altman': 576,\n",
       " 'divine': 577,\n",
       " 'outweighs': 578,\n",
       " 'mystique': 579,\n",
       " 'bush': 580,\n",
       " 'slick': 581,\n",
       " 'litmus': 582,\n",
       " 'fad': 583,\n",
       " 'blair': 584,\n",
       " 'isabelle': 585,\n",
       " 'tian': 586,\n",
       " 'grad': 587,\n",
       " 'dolby': 588,\n",
       " 'mire': 589,\n",
       " 'awakening': 590,\n",
       " 'squad': 591,\n",
       " 'patricio': 592,\n",
       " 'transition': 593,\n",
       " 'elie': 594,\n",
       " 'firsttimer': 595,\n",
       " 'free': 596,\n",
       " 'humming': 597,\n",
       " 'chickflicks': 598,\n",
       " 'thirteenyearold': 599,\n",
       " 'receiving': 600,\n",
       " 'lasting': 601,\n",
       " 'lapses': 602,\n",
       " 'slowness': 603,\n",
       " 'as': 604,\n",
       " 'grandmother': 605,\n",
       " 'standup': 606,\n",
       " 'emptiness': 607,\n",
       " 'tori': 608,\n",
       " 'inertia': 609,\n",
       " 'conversations': 610,\n",
       " 'karen': 611,\n",
       " 'rapport': 612,\n",
       " 'maze': 613,\n",
       " 'facades': 614,\n",
       " 'pseudorockvideo': 615,\n",
       " 'delineate': 616,\n",
       " 'inconsistent': 617,\n",
       " 'starry': 618,\n",
       " 'fore': 619,\n",
       " 'disagreeable': 620,\n",
       " 'imagemongering': 621,\n",
       " 'sensitivity': 622,\n",
       " 'revolution': 623,\n",
       " 'imaxy': 624,\n",
       " 'recreated': 625,\n",
       " 'ward': 626,\n",
       " 'gargantuan': 627,\n",
       " 'strands': 628,\n",
       " 'comically': 629,\n",
       " 'business': 630,\n",
       " 'editing': 631,\n",
       " 'troopers': 632,\n",
       " 'robotically': 633,\n",
       " 'theme': 634,\n",
       " 'raise': 635,\n",
       " 'seem': 636,\n",
       " 'adept': 637,\n",
       " 'special': 638,\n",
       " 'curiosity': 639,\n",
       " 'unforced': 640,\n",
       " 'southern': 641,\n",
       " 'adorably': 642,\n",
       " 'eroticized': 643,\n",
       " 'approaches': 644,\n",
       " 'hankypanky': 645,\n",
       " 'coldfish': 646,\n",
       " 'continues': 647,\n",
       " 'ethos': 648,\n",
       " 'dense': 649,\n",
       " 'existent': 650,\n",
       " 'surfaceobsession': 651,\n",
       " 'chomp': 652,\n",
       " 'despair': 653,\n",
       " 'relationship': 654,\n",
       " 'insatiable': 655,\n",
       " 'relegated': 656,\n",
       " 'venturesome': 657,\n",
       " 'directorial': 658,\n",
       " 'variant': 659,\n",
       " 'shoot': 660,\n",
       " 'peopled': 661,\n",
       " 'persona': 662,\n",
       " 'unimaginable': 663,\n",
       " 'impatient': 664,\n",
       " 'celebrities': 665,\n",
       " 'conservative': 666,\n",
       " 'highconcept': 667,\n",
       " 'voices': 668,\n",
       " 'civics': 669,\n",
       " 'grounded': 670,\n",
       " 'consigned': 671,\n",
       " 'das': 672,\n",
       " 'confounded': 673,\n",
       " 'definition': 674,\n",
       " 'mordantly': 675,\n",
       " 'insanity': 676,\n",
       " 'calibre': 677,\n",
       " 'mosque': 678,\n",
       " 'wander': 679,\n",
       " 'able': 680,\n",
       " 'jeanette': 681,\n",
       " 'meetsjohn': 682,\n",
       " 'hunnam': 683,\n",
       " 'mailorder': 684,\n",
       " 'appropriate': 685,\n",
       " 'incidents': 686,\n",
       " 'robberies': 687,\n",
       " 'field': 688,\n",
       " 'wellcontructed': 689,\n",
       " 'italicized': 690,\n",
       " 'departments': 691,\n",
       " 'guts': 692,\n",
       " 'slump': 693,\n",
       " 'kibosh': 694,\n",
       " 'fragmentary': 695,\n",
       " 'novelty': 696,\n",
       " 'pastafagioli': 697,\n",
       " 'friends': 698,\n",
       " 'christ': 699,\n",
       " 'looselyconnected': 700,\n",
       " 'backseat': 701,\n",
       " 'exhibits': 702,\n",
       " 'yawn': 703,\n",
       " 'hyphenate': 704,\n",
       " 'longfaced': 705,\n",
       " 'thornberry': 706,\n",
       " 'creed': 707,\n",
       " 'scribe': 708,\n",
       " 'faster': 709,\n",
       " 'perennial': 710,\n",
       " 'promisingly': 711,\n",
       " 'boombam': 712,\n",
       " 'phillip': 713,\n",
       " 'tales': 714,\n",
       " 'due': 715,\n",
       " 'aragorn': 716,\n",
       " 'faced': 717,\n",
       " 'computergenerated': 718,\n",
       " 'tardier': 719,\n",
       " 'underlay': 720,\n",
       " 'dani': 721,\n",
       " 'seeking': 722,\n",
       " 'bubble': 723,\n",
       " 'unschooled': 724,\n",
       " 'opportunists': 725,\n",
       " 'hannabarbera': 726,\n",
       " 'fiend': 727,\n",
       " 'daniel': 728,\n",
       " 'alain': 729,\n",
       " 'marvin': 730,\n",
       " 'glover': 731,\n",
       " 'book': 732,\n",
       " 'nonetoofunny': 733,\n",
       " 'invitingly': 734,\n",
       " 'carry': 735,\n",
       " 'keep': 736,\n",
       " 'rahrah': 737,\n",
       " 'critical': 738,\n",
       " 'fumbled': 739,\n",
       " 'rosenthal': 740,\n",
       " 'startle': 741,\n",
       " 'redgrave': 742,\n",
       " 'leash': 743,\n",
       " 'wretched': 744,\n",
       " 'diciness': 745,\n",
       " 'minkoff': 746,\n",
       " 'laura': 747,\n",
       " 'brit': 748,\n",
       " 'unexpectedly': 749,\n",
       " 'parallels': 750,\n",
       " 'cutes': 751,\n",
       " 'remade': 752,\n",
       " 'bedfellows': 753,\n",
       " 'sterile': 754,\n",
       " 'honest': 755,\n",
       " 'serenity': 756,\n",
       " 'touching': 757,\n",
       " 'serviceability': 758,\n",
       " 'qualities': 759,\n",
       " 'useful': 760,\n",
       " 'unseen': 761,\n",
       " 'rosecolored': 762,\n",
       " 'glancing': 763,\n",
       " 'thoughtless': 764,\n",
       " 'fairly': 765,\n",
       " 'visual': 766,\n",
       " 'visionary': 767,\n",
       " 'displays': 768,\n",
       " 'graphic': 769,\n",
       " 'brains': 770,\n",
       " 'typed': 771,\n",
       " 'perkiness': 772,\n",
       " 'camerawork': 773,\n",
       " 'unfold': 774,\n",
       " 'gentility': 775,\n",
       " 'revived': 776,\n",
       " 'determined': 777,\n",
       " 'freakish': 778,\n",
       " 'alltoohuman': 779,\n",
       " 'valid': 780,\n",
       " 'especially': 781,\n",
       " 'easier': 782,\n",
       " 'feat': 783,\n",
       " 'dolly': 784,\n",
       " 'd': 785,\n",
       " 'feet': 786,\n",
       " 'teendom': 787,\n",
       " 'rollerblades': 788,\n",
       " 'grouchy': 789,\n",
       " 'grosses': 790,\n",
       " 'blisteringly': 791,\n",
       " 'kaos': 792,\n",
       " 'pinks': 793,\n",
       " 'imagery': 794,\n",
       " 'expedience': 795,\n",
       " 'bawdy': 796,\n",
       " 'soulful': 797,\n",
       " 'bui': 798,\n",
       " 'computer': 799,\n",
       " 'zealand': 800,\n",
       " 'sermonize': 801,\n",
       " 'worrying': 802,\n",
       " 'reflections': 803,\n",
       " 'belinsky': 804,\n",
       " 'uncharismatically': 805,\n",
       " 'ayurveda': 806,\n",
       " 'overamorous': 807,\n",
       " 'architect': 808,\n",
       " 'distasteful': 809,\n",
       " 'fix': 810,\n",
       " 'introduces': 811,\n",
       " 'score': 812,\n",
       " 'tunnels': 813,\n",
       " 'willis': 814,\n",
       " 'immortal': 815,\n",
       " 'swooping': 816,\n",
       " 'imitating': 817,\n",
       " 'drawbacks': 818,\n",
       " 'civic': 819,\n",
       " 'putters': 820,\n",
       " 'selfindulgence': 821,\n",
       " 'sailor': 822,\n",
       " 'tendencies': 823,\n",
       " 'dungeons': 824,\n",
       " 'explosion': 825,\n",
       " 'kin': 826,\n",
       " 'seizing': 827,\n",
       " 'paradoxically': 828,\n",
       " 'regurgitates': 829,\n",
       " 'cooks': 830,\n",
       " 'silver': 831,\n",
       " 'leather': 832,\n",
       " 'tentative': 833,\n",
       " 'conspiracies': 834,\n",
       " 'cronenberg': 835,\n",
       " 'robinson': 836,\n",
       " 'goes': 837,\n",
       " 'erotic': 838,\n",
       " 'suspecting': 839,\n",
       " 'selby': 840,\n",
       " 'initially': 841,\n",
       " 'visit': 842,\n",
       " 'amini': 843,\n",
       " 'urgent': 844,\n",
       " 'tron': 845,\n",
       " 'marina': 846,\n",
       " 'tremors': 847,\n",
       " 'actors': 848,\n",
       " 'verdict': 849,\n",
       " 'sprawl': 850,\n",
       " 'hymn': 851,\n",
       " 'grandkids': 852,\n",
       " 'invited': 853,\n",
       " 'waxes': 854,\n",
       " 'creek': 855,\n",
       " 'hideandseek': 856,\n",
       " 'vulgarities': 857,\n",
       " 'believing': 858,\n",
       " 'stymied': 859,\n",
       " 'agreement': 860,\n",
       " 'iwai': 861,\n",
       " 'wilson': 862,\n",
       " 'uplifting': 863,\n",
       " 'sounding': 864,\n",
       " 'regimented': 865,\n",
       " 'peculiar': 866,\n",
       " 'intimacy': 867,\n",
       " 'evolution': 868,\n",
       " 'prevents': 869,\n",
       " 'strip': 870,\n",
       " 'strain': 871,\n",
       " 'girlmeetsgirl': 872,\n",
       " 'diamond': 873,\n",
       " 'amusements': 874,\n",
       " 'served': 875,\n",
       " 'hoopla': 876,\n",
       " 'humiliated': 877,\n",
       " 'adapted': 878,\n",
       " 'celebstrewn': 879,\n",
       " 'greasy': 880,\n",
       " 'beaten': 881,\n",
       " 'need': 882,\n",
       " 'expose': 883,\n",
       " 'room': 884,\n",
       " 'brimming': 885,\n",
       " 'swaying': 886,\n",
       " 'tick': 887,\n",
       " 'seasonal': 888,\n",
       " 'swathe': 889,\n",
       " 'gon': 890,\n",
       " 'boy': 891,\n",
       " 'made': 892,\n",
       " 'subtle': 893,\n",
       " 'evening': 894,\n",
       " 'overlyfamiliar': 895,\n",
       " 'trivialize': 896,\n",
       " 'oftbrilliant': 897,\n",
       " 'horrendously': 898,\n",
       " 'burr': 899,\n",
       " 'chicagobased': 900,\n",
       " 'spider': 901,\n",
       " 'normally': 902,\n",
       " 'flexible': 903,\n",
       " 'saccharine': 904,\n",
       " 'staggeringly': 905,\n",
       " 'sentence': 906,\n",
       " 'squeeze': 907,\n",
       " 'elysian': 908,\n",
       " 'fuse': 909,\n",
       " 'begley': 910,\n",
       " 'scenic': 911,\n",
       " 'hopelessly': 912,\n",
       " 'heroine': 913,\n",
       " 'muckraking': 914,\n",
       " 'commenting': 915,\n",
       " 'lucas': 916,\n",
       " 'eurotrash': 917,\n",
       " 'jolting': 918,\n",
       " 'frank': 919,\n",
       " 'complexly': 920,\n",
       " 'drawing': 921,\n",
       " 'bruin': 922,\n",
       " 'dreadfully': 923,\n",
       " 'storytelling': 924,\n",
       " 'pinochet': 925,\n",
       " 'unamusing': 926,\n",
       " 'heroism': 927,\n",
       " 'reno': 928,\n",
       " 'kirshner': 929,\n",
       " 'virtual': 930,\n",
       " 'therapydependent': 931,\n",
       " 'creatively': 932,\n",
       " 'derivativeness': 933,\n",
       " 'eckstraordinarily': 934,\n",
       " 'hugh': 935,\n",
       " 'alagna': 936,\n",
       " 'buries': 937,\n",
       " 'trust': 938,\n",
       " 'repartee': 939,\n",
       " 'therapeutic': 940,\n",
       " 'slickest': 941,\n",
       " 'sensitively': 942,\n",
       " 'kiltwearing': 943,\n",
       " 'lunar': 944,\n",
       " 'lower': 945,\n",
       " 'sascha': 946,\n",
       " 'broaches': 947,\n",
       " 'leatherbound': 948,\n",
       " 'bergmanesque': 949,\n",
       " 'pushed': 950,\n",
       " 'rifkin': 951,\n",
       " 'welcomes': 952,\n",
       " 'choreography': 953,\n",
       " 'parapsychological': 954,\n",
       " 'manages': 955,\n",
       " 'species': 956,\n",
       " 'menzel': 957,\n",
       " 'chung': 958,\n",
       " 'pootie': 959,\n",
       " 'freshness': 960,\n",
       " 'fierce': 961,\n",
       " 'rushed': 962,\n",
       " 'ringside': 963,\n",
       " 'sellers': 964,\n",
       " 'authentic': 965,\n",
       " 'outtakes': 966,\n",
       " 'thi': 967,\n",
       " 'evoking': 968,\n",
       " 'oodles': 969,\n",
       " 'overview': 970,\n",
       " 'crawl': 971,\n",
       " 'griffith': 972,\n",
       " 'hokey': 973,\n",
       " 'rescue': 974,\n",
       " 'messiness': 975,\n",
       " 'chase': 976,\n",
       " 'needs': 977,\n",
       " 'deliriously': 978,\n",
       " 'margarita': 979,\n",
       " 'subordinate': 980,\n",
       " 'peels': 981,\n",
       " 'yasujiro': 982,\n",
       " 'trinity': 983,\n",
       " 'defend': 984,\n",
       " 'camp': 985,\n",
       " 'try': 986,\n",
       " 'crosscountry': 987,\n",
       " 'ragged': 988,\n",
       " 'steeped': 989,\n",
       " 'mannered': 990,\n",
       " 'overstays': 991,\n",
       " 'kazan': 992,\n",
       " 'unstable': 993,\n",
       " 'lightfooted': 994,\n",
       " 'toss': 995,\n",
       " 'excess': 996,\n",
       " 'mainland': 997,\n",
       " 'gray': 998,\n",
       " 'charismatic': 999,\n",
       " 'speak': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set = set()\n",
    "for l in words:\n",
    "    for e in l:\n",
    "        word_set.add(e)\n",
    "        \n",
    "vocabulary = {word: ii for ii, word in enumerate(word_set, 1)}\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодуємо фрази відповідно до словника:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [5051, 9606, 16001, 9355, 4084, 10604, 9518, 9...\n",
       "1    [5051, 9606, 16001, 9355, 4084, 10604, 9518, 9...\n",
       "2                                         [5051, 9606]\n",
       "3                                               [5051]\n",
       "4                                               [9606]\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = words.apply(lambda l: [vocabulary[word] for word in l])\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Створюємо матрицю властивостей. Оскільки масиви токенів є різної розмірності, то зрівняємо їх, дописуючи  нулі наприкінці:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5051,  9606, 16001,  9355,  4084, 10604,  9518,  9992,  7553,\n",
       "         2327,  1977,  4723, 10604,   312,  2327, 13845,  1977,  4723,\n",
       "        10604,  5269, 10461, 16001, 12583,  9330,  6631,  8636, 15855,\n",
       "        16001, 12583, 13493, 11583, 15632, 16001,  5051, 13281,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0],\n",
       "       [ 5051,  9606, 16001,  9355,  4084, 10604,  9518,  9992,  7553,\n",
       "         2327,  1977,  4723, 10604,   312,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0],\n",
       "       [ 5051,  9606,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0],\n",
       "       [ 5051,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0],\n",
       "       [ 9606,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The longest phrase\n",
    "max_len = tokens.str.len().max()\n",
    "print(max_len)\n",
    "\n",
    "all_tokens = np.array([t for t in tokens])\n",
    "features = np.zeros((len(all_tokens), max_len), dtype=int)\n",
    "for i, row in enumerate(all_tokens):\n",
    "    features[i, :len(row)] = row\n",
    "\n",
    "# Print first 5 values of the feature matrix \n",
    "features[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Варто зазначити, що побудова графіків кореляції між властивостями (колонками) не має сенсу, адже властивості жодним чином не впливають одна на одну."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оскільки ми вирішуємо задачу логістичної регресії (бінарної класифікації), то замінимо значення оцінок на 0 і 1 за таким принципом: 0-1 позначимо як 0 (негативний), а 2-4 - як 1(позитивний; нейтральні коментарі теж вважатиемо позитивними)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "156055    1\n",
       "156056    0\n",
       "156057    1\n",
       "156058    1\n",
       "156059    1\n",
       "Name: Sentiment, Length: 156060, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train[\"Sentiment\"].apply(lambda i: 0 if i < 2 else 1)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Algorithm selection\n",
    "\n",
    "Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124848, 48), (124848,), (31212, 48), (31212,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size = 0.2, shuffle = True, stratify = target)\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "max_iters = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sklearn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vika\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', max_iter=max_iters, tol=1e-10)\n",
    "clf = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = clf.predict(X_train)\n",
    "Y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results evaluation for training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77844\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted\t0\t1\n",
      "Actual\n",
      "0\t\t299\t27177\n",
      "1\t\t484\t96888\n",
      "\n",
      "Precision: 0.78095\n",
      "\n",
      "Recall: 0.99503\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc_scr = accuracy_score(Y_train, Y_train_pred)\n",
    "print(\"Accuracy: {:.5f}\\n\".format(acc_scr))\n",
    "\n",
    "# Confusion Matrix:\n",
    "conf_mtrx = confusion_matrix(Y_train, Y_train_pred)\n",
    "print(\"Confusion Matrix:\\nPredicted\\t0\\t1\\nActual\\n0\\t\\t{}\\t{}\\n1\\t\\t{}\\t{}\".format(conf_mtrx[0][0], conf_mtrx[0][1],conf_mtrx[1][0],conf_mtrx[1][1]))\n",
    "\n",
    "# Precision\n",
    "prec = precision_score(Y_train, Y_train_pred)\n",
    "print(\"\\nPrecision: {:.5f}\".format(prec))\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(Y_train, Y_train_pred)\n",
    "print(\"\\nRecall: {:.5f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results evaluation for test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77851\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted\t0\t1\n",
      "Actual\n",
      "0\t\t76\t6793\n",
      "1\t\t120\t24223\n",
      "\n",
      "Precision: 0.78098\n",
      "\n",
      "Recall: 0.99507\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc_scr = accuracy_score(Y_test, Y_test_pred)\n",
    "print(\"Accuracy: {:.5f}\\n\".format(acc_scr))\n",
    "\n",
    "# Confusion Matrix:\n",
    "conf_mtrx = confusion_matrix(Y_test, Y_test_pred)\n",
    "print(\"Confusion Matrix:\\nPredicted\\t0\\t1\\nActual\\n0\\t\\t{}\\t{}\\n1\\t\\t{}\\t{}\".format(conf_mtrx[0][0], conf_mtrx[0][1],conf_mtrx[1][0],conf_mtrx[1][1]))\n",
    "\n",
    "# Precision\n",
    "prec = precision_score(Y_test, Y_test_pred)\n",
    "print(\"\\nPrecision: {:.5f}\".format(prec))\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(Y_test, Y_test_pred)\n",
    "print(\"\\nRecall: {:.5f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X_new = (X - mean) / std\n",
    "    return X_new, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X(X):\n",
    "    m = X.shape[0]\n",
    "    ones = np.ones((m, 1))\n",
    "    X_new = np.column_stack((ones, X))\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X, theta):\n",
    "    z = np.dot(X, theta)\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    if m == 0:\n",
    "        return None\n",
    "    \n",
    "    J = (-y * np.log(h(X, theta)) - (1 - y) * np.log(1 - h(X, theta))).mean()\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_theta(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    if m == 0:\n",
    "        return None\n",
    "\n",
    "    d_theta = np.dot(X.T, (h(X, theta) - y)) / m\n",
    "    \n",
    "    return d_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, epsilon, num_iters, print_J = True):\n",
    "    m = X.shape[0]\n",
    "    J_history = []\n",
    "    \n",
    "    J = cost_function(X, y, theta)\n",
    "    \n",
    "    if print_J == True:\n",
    "        print(J)\n",
    "    J_history.append(J)\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        delta = derivative_theta(X, y, theta)\n",
    "        theta = theta - alpha * delta\n",
    "        \n",
    "        J = cost_function(X, y, theta)\n",
    "        \n",
    "        J_history.append(J)\n",
    "        \n",
    "        if i % 1000 == 0 and print_J == True:\n",
    "            print(J)\n",
    "        \n",
    "        if abs(J-J_history[-2]) < epsilon:\n",
    "            break\n",
    "            \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    X_test_proc = prepare_X(X)\n",
    "    predictions = h(X_test_proc, theta)\n",
    "    return predictions.round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "max_iters = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, mean, std = normalize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_X(X_new)\n",
    "Y_new = Y_train.values.reshape((X_train.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#theta = np.zeros((X_new.shape[1], 1))\n",
    "theta = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "theta.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76952107  0.03013006 -0.00289988 -0.03841137 -0.06337455 -0.04375283\n",
      " -0.053813   -0.05694411 -0.04450165 -0.02912933 -0.0326578  -0.01906393\n",
      " -0.01331566 -0.01096458 -0.00522701 -0.01672952 -0.00671365 -0.00642675\n",
      " -0.0062127  -0.01430794 -0.0351233   0.00539657  0.01165963 -0.00612765\n",
      " -0.0157313  -0.00887422 -0.01367698  0.00209491  0.00698563  0.03109192\n",
      "  0.05475777  0.02886177  0.05314273  0.01398162 -0.00988267 -0.03908758\n",
      " -0.04421933 -0.06468078 -0.09213595 -0.0838834  -0.13108594 -0.16674306\n",
      " -0.19281795 -0.2079626  -0.23422611 -0.23537826 -0.25778189 -0.26394997\n",
      " -0.26674429] 9227\n"
     ]
    }
   ],
   "source": [
    "new_theta, Js = gradient_descent(X_new, Y_train, theta, alpha, 1e-7, max_iters, False)\n",
    "print(new_theta, len(Js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vika\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = predict(X_train, new_theta)\n",
    "print(Y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 1. 1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vika\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "Y_test_pred = predict(X_test, new_theta)\n",
    "print(Y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results evaluation for training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46869\n",
      "\n",
      "\tConfusion Matrix:\n",
      "Predicted    0.0    1.0\n",
      "Actual                 \n",
      "0          21781   5695\n",
      "1          60638  36734\n",
      "\n",
      "Precision: 0.86578\n",
      "\n",
      "Recall: 0.37725\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc_scr = accuracy_score(Y_train, Y_train_pred)\n",
    "print(\"Accuracy: {:.5f}\\n\".format(acc_scr))\n",
    "\n",
    "# Confusion Matrix:\n",
    "conf_mtrx = pd.crosstab(Y_train, Y_train_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(\"\\tConfusion Matrix:\\n{}\".format(conf_mtrx))\n",
    "\n",
    "# Precision\n",
    "prec = conf_mtrx[1][1]/(conf_mtrx[1][1] + conf_mtrx[1][0])\n",
    "print(\"\\nPrecision: {:.5f}\".format(prec))\n",
    "\n",
    "# Recall\n",
    "recall = conf_mtrx[1][1]/(conf_mtrx[1][1] + conf_mtrx[0][1])\n",
    "print(\"\\nRecall: {:.5f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results evaluation for test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47110\n",
      "\n",
      "\tConfusion Matrix:\n",
      "Predicted    0.0   1.0\n",
      "Actual                \n",
      "0           5460  1409\n",
      "1          15099  9244\n",
      "\n",
      "Precision: 0.86774\n",
      "\n",
      "Recall: 0.37974\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc_scr = accuracy_score(Y_test, Y_test_pred)\n",
    "print(\"Accuracy: {:.5f}\\n\".format(acc_scr))\n",
    "\n",
    "# Confusion Matrix:\n",
    "conf_mtrx = pd.crosstab(Y_test, Y_test_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(\"\\tConfusion Matrix:\\n{}\".format(conf_mtrx))\n",
    "\n",
    "# Precision\n",
    "prec = conf_mtrx[1][1]/(conf_mtrx[1][1] + conf_mtrx[1][0])\n",
    "print(\"\\nPrecision: {:.5f}\".format(prec))\n",
    "\n",
    "# Recall\n",
    "recall = conf_mtrx[1][1]/(conf_mtrx[1][1] + conf_mtrx[0][1])\n",
    "print(\"\\nRecall: {:.5f}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
